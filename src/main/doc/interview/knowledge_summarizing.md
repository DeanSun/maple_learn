# spring

1. springboot 启动流程
    + Springboot的启动，主要创建了配置环境(environment)、事件监听(listeners)、应用上下文(applicationContext)，并基于以上条件，在容器中开始实例化我们需要的Bean
2. 对spring cloud alibaba了解吗？都了解哪些组件
    + spring cloud alibaba: 它是由一些阿里巴巴的开源组件和云产品组成的。
    + 主要功能：
        + 服务限流降级：默认支持 Servlet、Feign、RestTemplate、Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。
        + 服务注册与发现：适配 SpringCloud 服务注册与发现标准，默认集成了 Ribbon的支持。
        + 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新
        + 消息驱动能力：基于SpringCloudStream为微服务构建消息驱动能力
        + 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。
        + 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。
    + 组件：
        + Sentinel：面向分布式服务架构的轻量级流量控制产品，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助您保护服务的稳定性。
        + Nacos：阿里巴巴推出来的一个新开源项目，这是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。
        + RocketMQ：分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。
        + Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。
        + Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。
        + Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。
    + 参考：  
      https://www.jianshu.com/p/9a8d94c0c90c
3. springboot controller是单例的嘛，为什么要关注单例？

4. 讲述一下 SpringBoot 自动装配原理？
    + 什么是 SpringBoot 自动装配？
        + 大概可以把 @SpringBootApplication看作是 @Configuration、@EnableAutoConfiguration、@ComponentScan 注解的集合。
            1. @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制
                + EnableAutoConfiguration 只是一个简单地注解，自动装配核心功能的实现实际是通过 AutoConfigurationImportSelector类。
            2. @Configuration：允许在上下文中注册额外的 bean 或导入其他配置类
            3. @ComponentScan： 扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。如下图所示，容器中将排除TypeExcludeFilter和AutoConfigurationExcludeFilter。
    + Spring Boot 通过@EnableAutoConfiguration开启自动装配，通过 SpringFactoriesLoader 最终加载META-INF/spring.factories中的自动配置类实现自动装配，自动配置类其实就是通过@Conditional按需加载的配置类，想要其生效必须引入spring-boot-starter-xxx包实现起步依赖

5. spring 事务
    + 事务：事务是逻辑上的一组操作，要么都执行，要么都不执行。  
      注意事项：事务能否生效数据库引擎是否支持事务是关键。比如常用的 MySQL 数据库默认使用支持事务的innodb引擎。但是，如果把数据库引擎变为 myisam，那么程序也就不再支持事务了！
    + 事务的特性（ACID）了解么?
        + 原子性（Atomicity）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。
        + 一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。
        + 隔离性（Isolation）： 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。
        + 持久性（Durability）:事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。
    + Spring 支持两种方式的事务管理： 1)编程式事务管理 2）声明式事务管理 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多）。
    + Spring 事务管理接口介绍 :
        + PlatformTransactionManager:（平台）事务管理器，Spring 事务策略的核心。
        + TransactionDefinition： 事务定义信息(事务隔离级别、传播行为、超时、只读、回滚规则)。
        + TransactionStatus： 事务运行状态。
    + PlatformTransactionManager:事务管理接口 Spring 并不直接管理事务，而是提供了多种事务管理器 。
    + TransactionDefinition:事务属性 事务属性可以理解成事务的一些基本配置，描述了事务策略如何应用到方法上。
    + TransactionDefinition 接口中定义了 5 个方法以及一些表示事务属性的常量比如隔离级别、传播行为等等。
    ```
        package org.springframework.transaction;
        
        import org.springframework.lang.Nullable;
    
        public interface TransactionDefinition {
        int PROPAGATION_REQUIRED = 0;
        int PROPAGATION_SUPPORTS = 1;
        int PROPAGATION_MANDATORY = 2;
        int PROPAGATION_REQUIRES_NEW = 3;
        int PROPAGATION_NOT_SUPPORTED = 4;
        int PROPAGATION_NEVER = 5;
        int PROPAGATION_NESTED = 6;
        int ISOLATION_DEFAULT = -1;
        int ISOLATION_READ_UNCOMMITTED = 1;
        int ISOLATION_READ_COMMITTED = 2;
        int ISOLATION_REPEATABLE_READ = 4;
        int ISOLATION_SERIALIZABLE = 8;
        int TIMEOUT_DEFAULT = -1;
        // 返回事务的传播行为，默认值为 REQUIRED。
        int getPropagationBehavior();
        //返回事务的隔离级别，默认值是 DEFAULT
        int getIsolationLevel();
        // 返回事务的超时时间，默认值为-1。如果超过该时间限制但事务还没有完成，则自动回滚事务。
        int getTimeout();
        // 返回是否为只读事务，默认值为 false
        boolean isReadOnly();
        
            @Nullable
            String getName();
        }
    ```
    + TransactionStatus:事务状态 TransactionStatus接口用来记录事务的状态 该接口定义了一组方法,用来获取或判断事务的相应状态信息。  
      TransactionStatus 接口接口内容如下：
    ```
        public interface TransactionStatus{
           boolean isNewTransaction(); // 是否是新的事务
           boolean hasSavepoint(); // 是否有恢复点
           void setRollbackOnly();  // 设置为只回滚
           boolean isRollbackOnly(); // 是否为只回滚
           boolean isCompleted; // 是否已完成
        } 
   ```
6. spring的工作原理？

7. springMVC的工作原理？

8. spring事务失效的原因？

# 数据库

1. Mysql
    + Mysql 常用内置函数都有哪些？
        + 数学函数   
          ABS(x)：返回x的绝对值  
          BIN(x)：返回x的二进制（OCT返回八进制，HEX返回十六进制）  
          CEILING(x)：返回大于x的最小整数值  
          EXP(x)：返回值e（自然对数的底）的x次方  
          FLOOR(x)：返回小于x的最大整数值  
          GREATEST(x1,x2,...,xn)：返回集合中最大的值  
          LEAST(x1,x2,...,xn): 返回集合中最小的值  
          LN(x): 返回x的自然对数  
          LOG(x,y): 返回x的以y为底的对数  
          MOD(x,y): 返回x/y的模（余数）  
          PI(): 返回pi的值（圆周率）  
          RAND(): 返回０到１内的随机值,可以通过提供一个参数(种子)使RAND()随机数生成器生成一个指定的值。  
          ROUND(x,y): 返回参数x的四舍五入的有y位小数的值  
          SIGN(x): 返回代表数字x的符号的值  
          SQRT(x): 返回一个数的平方根  
          TRUNCATE(x,y): 返回数字x截短为y位小数的结果
        + 聚合函数  
          ASCII(char)：返回字符的ASCII码值  
          BIT_LENGTH(str)：返回字符串的比特长度  
          CONCAT(s1,s2...,sn)：将s1,s2...,sn连接成字符串  
          CONCAT_WS(sep,s1,s2...,sn)：将s1,s2...,sn连接成字符串，并用sep字符间隔  
          INSERT(str,x,y,instr)：将字符串str从第x位置开始，y个字符长的子串替换为字符串instr，返回结果  
          FIND_IN_SET(str,list)：分析逗号分隔的list列表，如果发现str，返回str在list中的位置  
          LCASE(str)或LOWER(str)：返回将字符串str中所有字符改变为小写后的结果  
          LEFT(str,x)：返回字符串str中最左边的x个字符  
          LENGTH(s)：返回字符串str中的字符数  
          LTRIM(str)：从字符串str中切掉开头的空格  
          POSITION(substr,str): 返回子串substr在字符串str中第一次出现的位置  
          QUOTE(str): 用反斜杠转义str中的单引号  
          REPEAT(str,srchstr,rplcstr): 返回字符串str重复x次的结果  
          REVERSE(str): 返回颠倒字符串str的结果  
          RIGHT(str,x): 返回字符串str中最右边的x个字符  
          RTRIM(str): 返回字符串str尾部的空格  
          STRCMP(s1,s2): 比较字符串s1和s2  
          TRIM(str): 去除字符串首部和尾部的所有空格  
          UCASE(str)或UPPER(str): 返回将字符串str中所有字符转变为大写后的结果

    + Mysql集群模式都有哪些，以及相应的使用场景

    + Mysql常见的优化手段

    + Mysql底层Btree的实现原理
        +

    + Mysql中查询条件类型与字段类型不一致，会有什么性能方面的影响嘛？

    + 锁机制与InnoDB锁算法
        + MyISAM和InnoDB存储引擎使用的锁：
            + MyISAM使用表级锁(table-level locking)
            + InnoDB支持行级锁(row-level locking)和表级锁，默认使用行级锁
        + 表级锁和行级锁对比
            + 表级锁: Mysql中锁定粒度量大的一种锁，对当前操作的整张表加锁，资源占用少，加锁快，不会出现死锁。锁定粒度大，很容易出现冲突的问题，并发度低，MyISAM和InnoDB都支持表级锁。
            + 行级锁：Mysql中锁定粒度最小的一种锁，只对当前操作的行进行加锁。行级锁能够大大减少数据库操作的冲突。并发度高，加锁开销大，加锁慢，容易出现死锁的情况。
        + InnoDB行级锁有以下几种：
            + Record Lock：对索引项加锁，锁定符合条件的行。其他不能修改和删除加锁项。
            + Gap Lock：对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。
            + Next-key Lock：锁定索引项本身和索引范围。即Record Lock和Gap Lock结合。可解决幻读问题。

        + 参考：https://blog.csdn.net/qq_34337272/article/details/80611486,
    + 锁分类
        + 表级锁和行级锁可以进一步划分为共享锁(s)和排它锁(x)
            + 共享锁(s)
                + 共享锁（Share Locks, ）
2. SQL Server
3. MongoDB
4. 数据库的优化方案

# 并发

1. 多个sync嵌套是程序怎么进行区分

2. 同步标记跟lock之间的区别
   <table>
   <thead>
   <tr>
   <td width="100"></td>
   <td>sync</td>
   <td>lock</td>
   </tr>
   </thead>
   <tbody>
   <tr>
   <td>存在层次</td>
   <td>java关键字，jvm层面</td> 
   <td>是一个接口</td>
   </tr>
   <tr>
   <td>锁的释放</td>
   <td>程序执行完释放锁;发生异常jvm释放锁</td>
   <td>在finally中必须释放锁，否则容易造成死锁的情况</td>
   </tr>
   <tr>
   <td>锁的获取</td>
   <td>A获取，B等待。A阻塞，B一直等待</td>
   <td>有多种获取锁的方式，尝试获取锁，有公平和不公平，有共享和独享。不同的锁实现AQS的方式不同</td>
   </tr>
   <td>锁状态</td>
   <td>无法判定</td>
   <td>可以判定</td>
   <tr>
   <td>锁类型</td>
   <td>可重入，不响应中断，非公平锁</td>
   <td>可重入，可判断，公平/非公平（二者皆可）</td>
   </tr>
   <tr>
   <td>性能</td>
   <td>少量同步</td>
   <td>大量同步</td>
   </tr>
   </tbody>
   </table>

3. 并发编程三要素？
    + 原子性：原子性指的就是一个或者多个操作，要么全部执行并且在执行过程中不被其他操作打断，要么就全部都不执行
    + 可见性：可见性是多个线程同时操作一个共享变量时，其中一个线程对共享变量进行修改后，其他线程能够立即看到修改后的结果
    + 有序性：程序的执行顺序按照代码的先后顺序执行

4. 创建线程的方式有哪些?
    + 集成Thread类创建线程类
    + 通过Runnable接口创建线程类
    + 通过Callable和Future创建线程
    + 通过线程池创建
5. Java线程具有五种基本状态
    + 新建状态(New): 当线程对象创建后，立即进入新建状态
    + 就绪状态(Runnable): 当调用线程对象的start（）方法，线程即进入就绪状态。处于就绪状态的线程，只是说明该线程已经准备好，随时可以响应CPU的任务调度，而不是说调用了start()方法后，该线程立即执行。
    + 运行状态(Running): 当CPU开始调度就绪状态的线程时，线程才可以进入运行状态。也就是说要是想让线程进入到运行状态，必须先让线程进入就绪状态。
    + 阻塞状态(Blocking)： 处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，停止执行，进入到阻塞状态，直到其进入到就绪状态，才能够再次被CPU调用进入运行状态。
        + 根据阻塞状态的原因不同，阻塞状态又可以分为三种：
            1. 等待阻塞 运行状态中的线程执行wait()方法，使本线程进入到等待阻塞状态
            2. 同步阻塞 线程在获取synchronized同步锁失败(因为被其他线程所占用),它会进入同步阻塞状态
            3. 其他阻塞 通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时，join()等待线程终止或者超时，或者I/O处理完毕时，线程重新转入就绪状态。
    + 死亡状态(Dead): 线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

6. 什么是线程池?
    + 线程池就是提前创建若干线程，如果有任务需要处理，线程池里的线程就会处理任务，处理完之后线程并不会被销毁，而是等待下一个任务。由于创建和销毁都是非常消耗系统资源的，所以当你想要频繁创建和销毁线程的时候就可以使用线程池来提升性能。

7. 四种线程池的创建：
    + newCachedThreadPool：创建一个可缓存线程池
    + newFixedThreadPool: 创建一个定长线程池，可控制线程最大并发数
    + newScheduledThreadPool: 创建一个定长线程池，支持定时及周期性任务执行
    + newSingleThreadExecutor: 创建一个单线程化的线程池，只有一个线程来执行任务。

8. 常用的并发工具类有哪些?
    + CountDownLatch、CyclicBarrier、Semephore、Exchanger

9. CyclicBarrier和CountDownLatch的区别？
    + CountDownLatch 是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。
    + CyclicBarrier让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。
    + CountDownLatch 计数只能使用一次，但是CyclicBarrier如字面意思一样，是一个可以循环使用的屏障，调用reset()方法后可以再次使用。
    + CyclicBarrier方法还有很多其他的功能接口方法。比如获取阻塞线程数量，获取阻塞的线程的是否被中断。

10. Synchronized的作用?
    + Synchronized关键字是用来控制线程同步的，可以保证在多线程环境中，只有一个线程可以执行代码。该关键字可以修饰代码块也可以修饰方法。

11. volatile关键字的作用?
    + 使用该关键字以后可以让多线程环境中，线程间可以共享变量信息，实现可见性；使用改关键字可以禁止指令重排序优化。

12. 什么是CAS？
    + CAS就是 Compare And Swap 的缩写，意思就是比较交换。 CAS是一种乐观锁。CAS包括三个操作数，内存位置、预期原值和新值。

13. CAS的问题：
    + CAS容易造成ABA问题： 一个线程将数值改成了b，然后又改回a，此时CAS是认为没有变化，其实是已经变化了，这个问题最好的解决办法就是版本号。每操作一次版本号+1.
    + 循环时间长开销大：自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销
    + 只能保证一个共享变量的原子操作：当一个共享变量执行操作时，可以使用自旋CAS的方式保证其原子性。但是多个共享变量操作时，这时候就需要加锁了。

14. 什么是Future?
    + 在实例化线程的时候，不论我们继承Thread还是实现Runnable接口，我们都得不到执行后的结果。但是通过实现Callback接口，并用Future可以来接收多线程的执行结果。Future表示一个可能还没有完成的异步任务的结果，针对这个结果可以添加Callback以便在任务成功或失败做出相应的操作。

15. 什么是AQS？
    + 它是Java底层一个同步工具类，用一个int类型的变量表示同步状态了，并提供了一系列CAS操作来管理这个同步状态。
    + AQS是一个用来构建锁和同步器的框架，使用AQS可以简单高效地构造出应用广泛的大量的同步器。例如：ReentrantLock，Semphore、ReentrantReadWriteLock、SynchronousQueue、FutureTask。

16. AQS的两种同步方式?
    + 独占式
        + ReentrantLock
    + 共享式
        + Semaphore、CountDownLatch

    混合的例如：ReentrantReadWriteLock

17. ReadWriteLock是什么?
    + ReadWriteLock是一个读写锁接口，ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。

18. FutureTask是什么？
    + 一个异步运算的任务。改类内可以传入一个Callable的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。由于FutureTask也是Runnable接口的实现类，所以FutureTask也可以放入线程池内。

19. synchronized和ReetrantLock的区别
    + 首先synchronized是java关键字，ReentrantLock是一个类，二者的本质区别。既然ReentrantLock既然是一个类那么他相比synchronized就具有更多的灵活性，可以被继承，可以有方法有更多的属性。
    + ReentrantLock体现扩展性最好的方面如下：
        + 可以设置获取锁的等待时间，有效避免死锁问题
        + 可以获取锁的信息
        + 可以灵活的实现多路通知
    + ReentrantLock底层调用的是Unsafe的park()方法加锁
    + synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。   
      synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。  
      不过两者的本质都是对对象监视器 monitor 的获取。

20. 乐观锁和悲观锁
    + 乐观锁：不进行加锁操作，乐观认为修改内存变量的时候没有人跟你有竞争的情况，通过比较-替换的操作来保证原子操作，如果替换失败就表明有对应的冲突操作，这样就有相应的重试逻辑。
    + 悲观锁：认为每次操作的时候都会有竞争的情况，所以在进行操作的时候必须先进行加锁操作。

21. 线程调度策略：线程调度器优先选择优先级最高的线程运行，但是如下几种情况发生以后，线程就会终止运行：
    + 线程体中调用了yield方法让出了对cpu的占用权利
    + 线程体中调用了sleep方法使线程进入睡眠状态
    + 线程由于IO操作受到阻塞
    + 另外一个更高优先级的线程出现
    + 在支持时间片的系统中，该线程的时间片用完

22. ConcurrentHashMap的并发度是什么？
    + ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势

23. 怎么唤醒一个阻塞的线程？
    + 如果线程是因为调用了wait(),sleep()或者join()方法而导致阻塞，可以中断线程，并且通过抛出InteruptException来唤醒它；如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。

24. 如果你提交任务时，线程池队列已满，这时会发生什么？
    + 如果使用的是无界队列LinkedBlockingQueue,继续添加任务到阻塞队列中等待执行，因为此无界队列可以近乎认为是一个无穷大的值，可以无限存放任务？？？？
    + 如果使用的是游街队列ArrayBlockingQueue，任务首先会被添加到ArrayBlockingQueue中，ArrayBlockingQueue满了，会根据maxmumPoolSize的值增加线程数量，如果增加了线程数量还是处理不过来，ArrayBlockingQueue继续满，那么则会使用拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy。

25. Semaphore有什么作用
    + Semaphore就是一个信号量，它的作用是限制某段代码块的并发数。

26. Java线程数过多会造成什么异常？
    1. 线程的生命周期的开销非常高
    2. 消耗过的CPU资源
    3. 降低稳定性

27. 高并发常见指标：响应时间(Response Time)、吞吐量(Throughput)、每秒查询率QPS(Query per second)、并发用户数

28. 响应时间：系统对请求做出相应时间

参考：  
https://blog.csdn.net/tanmomo/article/details/99671622
https://blog.csdn.net/w372426096/article/details/89914454

# 分布式

1. CAP
    + 简单描述cap
        + Consistency: Every read receives the most recent write or an error  
          一致性：所有节点访问同一份最新的数据副本
        + Availability: Every request receives a (non-error) response, without the guarantee that it contains the most recent write  
          可用性：非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。
        + Partition tolerance: The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes  
          分区容错性：分布式系统出现网络分区的时候，仍然能够对外提供服务。
    + 什么是网络分区？
        + 分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫网络分区。
    + 不是所谓的三选二？
        + 当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。简而言之就是：CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。 因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。
    + 分布式事务BASE理论？
        + BASE理论是对CAP的延伸和补充，是对CAP中的AP方案的一个补充，即使在选择AP方案的情况下，如何更好的最终达到C。BASE是基本可用，柔性状态，最终一致性三个短语的缩写，核心的思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性。
    + 参考：  
      https://juejin.cn/post/6844903936718012430
2. 分布式锁，是选择AP还是选择CP ？   
   这里实现分布式锁的方式选取了三种：
    + 基于数据库实现分布式锁
    + 基于redis实现分布式锁
    + 基于zookeeper实现分布式锁

3. zookeeper和Eureka的区别？
    + zookeeper选择CP
        + zookeep保证CP，即任何时刻对zookeeper的访问请求能得到一致性的数据结果，同时系统对网络分割具备容错性，但是它不能保证每次服务的可用性。从实际情况来分析，在使用zookeeper获取服务列表时，如果zk正在选举或者zk集群中半数以上的机器不可用，那么将无法获取数据。所以说，zk不能保证服务可用性。
    + eureka选择AP
        + eureka保证AP，eureka在设计时优先保证可用性，每一个节点都是平等的，一部分节点挂掉不会影响到正常节点的工作，不会出现类似zk的选举leader的过程，客户端发现向某个节点注册或连接失败，会自动切换到其他的节点，只要有一台eureka存在，就可以保证整个服务处在可用状态，只不过有可能这个服务上的信息并不是最新的信息。

4.

# 系统设计

1. 让你设计一个抢购系统你怎么进行设计
    + 设计重点是：高性能、一致性、高可用。
    + 设计原则：数据少，请求少，路径段、依赖少、不使用单点。
    + 技术要点：
        + 动静分离 URL唯一化、分离浏览者相关的因素（包括是否已登录、登录权限等）、分离时间因素、异步化地域因素、去掉cookie。
            + 使用缓存可以处理静态数据。
            + 动态数据处理通常由两种解决方案：ESI(Edge Side Include)方案和CSI(Client Side Include)方案。
                1. ESI方案：在web代理服务器上做动态内容请求，并将请求插入到静态页面内，当用户拿到页面的时候是一个完整的页面了。这中对服务器性能有影响，但是用户体验比较好。
                2. CSI方案：单独发起js请求，向服务器端进行资源请求。这种服务器性能更优，但是用户端请求可能会演示，体验稍差。
            + 动静分离架构方案：
                1. 实体机单机部署：
                    + 优点：没有网络瓶颈，大内存；提升命中率，减少Gzip压缩
                    + 缺点：CPU浪费，单个java进程很难打满CPU
                2. 统一Cache层：
                    + 优点：可以共享内存，最大化利用内存，不同系统间的内存可以动态切换，有效防御各种攻击
                    + 缺点：Cache层内部网络交换成为瓶颈；缓存服务器的网卡也是瓶颈；机器少风险较大，挂一台机器会影响很大一部分数据。
                    + 解决缺点的方法：对Cache做Hash分组，可以有效进行数据分散不会集中在一个节点上。
                3. CND：
                    + 优点：由运营商提供服务，自动提供由距离客户最近的服务器提供访问静态相关资源
                    + 缺点：靠近访问量比较集中的地区；距离主站较远；需要节点到主站间的网络稳定相对较好；节点容量大，不影响其他CDN太多资源。节点不要太多。
                    + CND部署的特点：
                        1. 整个页面缓存在客户端
                        2. 强制刷新页面，请求CDN
                        3. 实际有效请求只有用户对“抢购”按钮的点击

                        + 这样就可以实际有效的将大部分的静态数据缓存在客户端或者CDN那里，真正秒杀的时候只有局部的“抢购”按钮需要刷新。
        + 热点数据： 2/8原则，20%的数据占据80%的流量，这部分数据就是热点数据。
            + 热点：分为热点操作和热点数据。
            + 热点数据：分为静态热点数据和动态热点数据
                1. 静态热点数据：能够提前预测的热点数据。可以通过大数据分析出热点商品数据，比如通过成交记录，购物车记录等。
                2. 动态热点数据: 不能提前被预知的数据，系统在运行中临时出现产生的热点。
            + 发现热点数据：
                1. 发现静态热点数据：可以通过商业手段，比如强制卖家通过报名参加的方式筛选商品或者通过大数据分析买家的数据来筛选热门商品。
                2. 发现动态热点数据：构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点 Key，如 Nginx、缓存、RPC 服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。 建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上 Nginx 模块统计的热点 URL。
                   将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。
            + 处理热点数据：
                1. 优化：缓存热点数据。动静分离以后，可以长时间缓存静态数据。如果是临时热点数据，可以使用队列进行数据缓存，采购LRU的淘汰机制。
                2. 限制：可以进行商品ID哈希，然后根据哈希做分桶，这样就会有效的将热点商品的数据放在一个请求队列里，可以有效的防止高频热点数据的请求妨碍其他商品始终请求不到资源的问题。
                3. 隔离：将热点数据进行隔离，尽量不要因为热点商品影响主业务商品的运行。
                    + 业务隔离： 卖家搞促销报名，提前预知热点内容。
                    + 系统隔离： 将部署系统分组，可以分配单独的域名实现请求落到不同的集群。
                    + 数据隔离： 调用单独的缓存或者数据库
        + 流量削峰
            + 为何要削峰：可以让服务器处理变的更平稳；可以节省服务器的资源成本。
            + 思路：排队、答题、分层过滤
                1. 排队：用消息队列来缓冲瞬时流量，把同步的直接调用换成异步的间接推送
                2. 答题：一个是为了有效防止一些外挂程序等方式的作弊；另一个是延缓请求。
                3. 分层过滤：就是将无用请求过滤，只保留最后的有效请求再处理。
    + 影响性能的因素，如何提高性能：
        + 性能： 真正对性能有影响的就是CPU执行时间。其次就是线程对QPS的影响
        + 如何发现瓶颈： 当QPS到达极限的时候，你的服务器CPU使用率是否达到95%，如果没有达到则说明你的程序还有提升的空间。
        + 真实项目中遇到的小问题：
            + 场景：一个只有三台服务器的小商城。面对业务方突然的促销。服务器直接瘫痪。这时候考虑问题的顺序：
                1. 服务器集群数量不够
                2. 请求中携带的数据过大，违背“架构设计原则中数据尽量小”的原则
                3. 直接访问数据库进行数据请求，导致数据库请求链接数不够，无法响应，达不到高并发的场景。需要加入缓存，cdn等方式。
                4. 缓存服务器响应不过来，扩大缓存集群。
                5. 由于连接数导致响应问题，需要进行web容器，ng，数据库，缓存等中间件的最大连接数，jvm调优等。
    + 秒杀过程中“减库存”设计的核心逻辑：
        + 下单减库存
        + 付款减库存
        + 预扣库存 利弊后面有相关描述。
    + 如何设计兜底方案：
      ![img.png](img.png)
        + 架构阶段：主要考虑可扩展性和容错性，尽量避免单机部署
        + 编码阶段：编码保证代码的健壮性，例如涉及远程调用问题时，要设置合理的超时退出机制，防止被其他系统拖垮，也要对调用的返回结果集有预期，防止返回的结果超出程序处理范围，最常见的做法就是对错误异常进行捕获，对无法预料的错误要有默认处理结果。
        + 测试阶段：测试主要是保证测试用例的覆盖度，保证最坏情况发生时，我们也有相应的处理流程。
        + 发布阶段：发布时也有一些地方需要注意，因为发布时最容易出现错误，因此要有紧急的回滚机制。
        + 运行阶段：运行时是系统的常态，系统大部分时间都会处于运行态，运行态最重要的是对系统的监控要准确及时，发现问题能够准确报警并且报警数据要准确详细，以便于排查问题。
        + 故障发生：故障发生时首先最重要的就是及时止损，例如由于程序问题导致商品价格错误，那就要及时下架商品或者关闭购买链接，防止造成重大资产损失。然后就是要能够及时恢复服务，并定位原因解决问题。
    + 抢购系统的业务特点：一般是库存有限，ID购买有数量限制，倒计时售卖。
    + 购买的业务流程：  
      查询商品详情->点击购买，库存校验->扣库存，创建订单->支付订单
    + 查看商品详情  
      倒计时开启售卖，时间主要是依赖于本地时间，但是会定时跟服务器进行时间同步
    + 点击购买，库存校验  
      库存校验，请求量大，需要进行快速响应。一般就是放入缓存，因为是分布式服务架构，一般使用redis。 一般会有后台系统进行抢购商品的配置，在配置完毕的时候进行缓存数据的缓存。
    + 扣库存，创建订单
        + 现象：扣库存最容易出现的问题就是【超卖】
        + 步骤：中间操作有这样两个步骤，因为有缓存保存了库存，这样就会有缓存和数据库一致性的要求。
            1. 扣缓存的库存
            2. 扣数据库的库存
        + 方案：
            + 方案一：下单减库存，当买家下单后，商品库存减去买家的数量  
              问题：下单预占库存，有恶意买家下单不付款，会导致大量买家无法正常买到商品，同样会导致商家也挣不到钱
            + 方案二：付款减库存，买家下单后，并不立即减库存，而是当成功付款以后，才减库存  
              问题：方案二解决了上述方案一出现的问题，但是超卖的问题就会随着而来，因为库存有限，所以有买家就会购买失败
        + 处理方式：
            + 一般系统会进行方案一的选择，即便有一些买家不付款，但是也会有很多买家会进行捡漏，不付款的买家会被商家踢出取消订单或者系统取消超市订单恢复库存。同时进行用户统计，存在恶意下单的客户会进行相应的记录，拉黑名单进行惩罚。
            + 分布式限流：解决的方法有很多，ng限制，业务系统有计数器法，漏斗法，令牌法。一般基于redis进行令牌限流，有很多组件，主流采用google提供的组件。
    + 支付订单
        + 异步化：当进行了有效的限流等操作以后，仍会有大量的请求进入业务系统，这时候大量的请求会对数据库造成很大的请求压力，这时候我们可以 把这种下单请求放入消息队列，将并发同步请求，改为串行异步请求。
    + 总结：
        1. 尽量进行请求拦截
        2. 保护数据库资源，使用缓存技术
        3. 同步操作转变为异步操作
        4. 针对超大流量的情况，可以采用如下方式：
            + 降级：所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。   
              降级方案可以这样设计：当秒杀流量达到 5w/s 时，把成交记录的获取从展示 20 条降级到只展示 5 条。“从 20 改到 5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。
            + 限流： 如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。  
              限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能 fast fail（快速失败）而拖垮系统。
            + 拒绝服务：如果限流还不能解决问题，最后一招就是直接拒绝服务了。  
              当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。例如秒杀系统，我们在如下几个环节设计过载保护：  
              在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝 HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护。   
              拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。

    + 参考:  
      https://blog.csdn.net/libra_ts/article/details/85198469  
      https://zhuanlan.zhihu.com/p/73659339

# 数据库

1. 数据库中导致索引失效都有哪些情况？

2. 为什么不推荐使用外键
    + 优点：数据强一致性;ER图可靠易读。
    + 缺点：级联问题;增加数据库压力;死锁问题:高并发场景下很容易造成死锁;开发不方便
    + 总结：
        + 如果是单机并且并发不高的情况，不需要性能调优，或者不能使用程序保证数据的一致性和完整性，可以使用外键
        + 如果为了高并发，分布式，使系统性更优，更好维护，不要使用外键

# 设计模式

1. 开发商常用的设计模式都有那些？
    + 模板方法模式：经典使用就是AQS共享和非共享获取和释放锁的实现
    + 工厂方法模式：spring实例工厂的实现
    + 代理模式：最简单的应用就是代理类将所有其他模块业务方法的调用进行封装

# 中间件

1. redis
    + redis 基本数据类型  
      Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。
    + redis是单线程还是多线程  
      redis4.0已经有了多线程的概念，但是默认是关闭的。并且redis多线程跟membercache是不同的，redis作者也强调，redis的单线程的处理能力很强，没有必要使用多线程。之所以加入了多线程是为了用来处理删除等速度较慢的指令。 redis之所以速度很快是因为底层使用的是IO多路复用，也就是reactor模型。这种模型跟java nio，linux epoll/poll的IO思路是一样的。select+轮循。同一个线程可以响应多个IO事件，异步非阻塞。多路指的是多个网络请求，复用指的就是同一个线程。 而且redis是内存式的，并且数据结构简单，也是它速度快的原因。
    + redis 集群方式有哪几种？
2. kafka
    + Kafka有四个核心API：Producer API;Consumer API;Stream API;Connector API
        + Producer API: 允许一个程序发布一串流式的数据到一个或者多个Kafka topic
        + Consumer API: 允许一个应用程序订阅一个或者多个topic，并且对发布给他们的流式数据进行处理
        + Stream API: 允许一个程序作为流处理器，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或者多个topic中去，在输入输出中进行有效的转换
        + Connector API: 允许构建并运行可重用的生产者或者消费者，将kafka topics连接到已存在的应用程序或者数据系统。
    + 为了理解 sendfile 的意义，从文件到套接字的通用传输路径是：
        + 操作系统从磁盘读取数据到内核空间的pagecache
        + 应用程序读取内核空间的数据到用户空间的缓存
        + 应用程序将数据（用户空间缓冲区）写回内核空间到套接字缓冲区(内核空间)
        + 操作系统将数据从套接字缓冲区（内核空间）复制到通过网络发送的NIC缓冲区  
          有四次copy操作和两次系统调用，效率很低。使用sendfile的方法，允许操作系统将数据从pagecahce直接发送到网络，这样避免重新复制数据。所以这种优化方式，只需要最后一步的copy操作，将数据复制到NIC缓冲区。

    + kafka客户端：生产者和消费者
        + 一致性：每一种客户端都可以配置为不同的一致性级别
            + 生产者：
                1. 等待所有同步副本可以确认消息
                2. 仅等待领导者确认消息
                3. 不等待确认
            + 消费者：
                1. 最多接收一次
                    + 对于最多一次消息传递，消费者从分区读取数据，提交它已读取的偏移量，然后处理消息。如果消费者在提交偏移和处理消息之间崩溃，它将从下一个偏移重新开始，而不处理消息。这将导致潜在的不期望的消息丢失。
                2. 至少接收一次
                    + 消费这从分区读取数据，处理数据，然后提交它处理的消息的偏移量。在这种情况下，消费者可能在处理消息和提交偏移之间崩溃，并且当消费者重新启动时将再次处理消息。这将导致下游系统中出现重复消息，但不会丢失数据。
                3. 接收每个消息一次
                    + 通过让消费者处理消息并将消息的输出与偏移一起提交给事务系统，可以确保一定交付。如果消费者崩溃，它可以重新读取最后提交的事务并从那里恢复处理。这不会导致数据丢失，也不会导致数据重复。但是这种方法会降低系统的吞吐量，因为每个消息和偏移都提交了事务。
            + 大多数Kafka消费者应用程序选择至少一次交付，因为它提高了吞吐率和正确性之间的最佳平衡。下游系统将以自己的方式进行重复消息的处理。
            + 该共识机制的原理是什么？
                + Kafka是一种分布式的、基于发布/订阅的消息处理模式
            + 该机制解决什么问题？
                + 解决了分布式系统中，消息的一致性和快速处理的问题。
            + 该机制如何在区块链系统中应用？
                + Fabric1.0系统中选用该机制提高系统的吞吐量，相比0.6版本的PBFT，该机制不会随着节点的增加而降低系统吞吐量。(可以随着节点增加增加Broker的数量，虽然成本有所增加，但总比性能太差好太多)
            + 该共识机制分为哪些步骤？
                + Push过程：Producer客户端发起写入请求，Broker根据消息分类将消息写入到一个Topic中的一个Partition中
                + Pull过程：Cusummer客户端发起访问请求，Broker根据访问消息的Topic、Partition和Offset找到对应的访问消息读取
            + 该共识机制的特征有哪些，需要满足哪些前提条件？
                + 特征：支持多线程处理，提高系统吞吐量；同时提供离线处理和实时处理，达到性能和需求的平衡。
            + 该共识机制的优点和缺点有哪些？
                + 优点：Kafka允许大量永久或临时消费者，节点允许随时加入和退出，不影响系统；支持多线程处理，具有可水平扩展、异步通信、高性能、高可用性和对节点故障的弹性，并支持自动恢复。在现实世界的数据系统中，这些特性使Kafka成为大规模数据系统组件之间通信和集成的理想选择。
                + 缺点：
            + 该共识机制的可能出现哪些问题，如何处理？
                + 在消费者获取消息时，需要让消费者处理消息并将消息的输出与偏移一起提交给事务系统，确保不会丢失未处理的消息，但是这样做需要再提交一次事务，从而导致系统性能下降。
                + 只能对同一个Topic中同一个Partition进行排序，且具有唯一性，不支持跨Partition跨Topic进行排序
            + 该共识机制存在哪些攻击，该如何处理？
                + 伪装生产者或者消费者进行数据的写入和读取。
                + 对应措施：
                    + 引入安全认证，如CA等，保证节点身份可靠。
                    + 引入权限控制：设计并实现Topic级别的权限模型。Topic的权限分为读，写，创建和删除。
            + 参考  
              https://blog.csdn.net/weixin_42121272/article/details/113582764

    + topic就是数据主题，是记录数据发布的地方，用以用来区分业务系统。topic一般都是多订阅模式，一个topic可以拥有一个或者多个消费者来订阅它的数据。 每个分区都是有序切顺序不可变的记录，并且不断追加到结构化的commit log文件。
    + offset：分区中每一条记录都会分配一个标识id，也就是我们所谓的offset，是用来标识每个分区记录的唯一标识。
    + 日志中的partition（分区）的用途：
        1. 当日志大小超过当台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，但是一个主题可以拥有多个分区，因此就可以处理无限量的数据。
        2. 可以作为并行的单元集。
            + 分布式：日志的分区partition （分布）在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性.每个分区都有一台 server 作为 “leader”，零台或者多台server作为 follwers 。leader server 处理一切对 partition （分区）的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers 中的一台服务器会自动成为新的 leader。每台 server 都会成为某些分区的 leader 和某些分区的
              follower，因此集群的负载是平衡的。
            + 生产者：生产可以可以将数据发布到所选的topic中。生产者负责将记录分配到topic的哪一个partition（分区）中。可以使用循环简单的实现负载均衡，也可以根据某些语义分区函数。
            + 消费者：

    + 传统的消息系统有两个模块：队列和发布-订阅。
        + 队列：消费者池从Server读取数据，每条记录被池子中的一个消费者消费
        + 发布-订阅：记录被广播到所有的消费者。
        + 二者的对比：
            + 队列的优点在于允许你将数据处理的过程分给多个消费者实例，使你可以扩展处理过程。不好的是，队列不是多订阅模式的，一旦一个进行消费了数据，该数据就会被丢弃
            + 发布-订阅允许你广播数据到多个进程，但是无法进行扩展处理，因为每条数据都会发送给所有的订阅者。
        + 消费组：在队列中是允许你将处理过程分发给一系列进程（消费组中的成员）。在发布-订阅模式中就是将消息广播给多个消费组。
    + 保证：
        + 生产者发送到指定的topic partition中的消息将按照顺序进行处理
        + 一个消费者实例按照日志中的顺序查看日志
        + 对于具有N个副本的主题，可以容忍N-1个服务器故障，从而保证不会丢失任何提交到日志中的记录。

    + 传统队列，在记录的时候虽然是有序的，但是当消费者是多个的时候，这样消息到达每个消费者的过程就是异步的，导致顺序失效，这样也就导致队列消息的消费需要的是同步消费，也就只允许一个进程来处理消息，不能并行处理。  
      Kafka的优势，topic中的partition就是一个并行的概念。能够为一个消费者池提供顺序保证和负载平衡，是通过partition分配给消费组中的消费者来实现的，一遍每个分区由消费组中的一个消费者来进行消费。众多分区保证了多个消费者的负载均衡，但是也要注意，消费者组中的消费者不能超过分区的数量。

    + Kafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统。
    +

    + KafKa的优点：解耦、冗余（副本）、扩展性、灵活性&峰值处理能力、可恢复性、顺序保证、缓冲、异步通信。

    + Kafka可不可以动态添加topic副本？

    + Kafka集群模式

    + Kafka经常应用的场景有哪些？

    + 给你几台服务器怎么高效设置Kafka

3. 常见MQ对比
    +

# 网络编程

1. netty:
    + I/O请求：
        + I/O调用阶段：用户进程向内核发起系统调用
        + I/O执行阶段：内核等待I/O请求处理完成返回

# 操作系统

1. linux文件系统：
    + 处理器设有两种模式：用户模式和内核模式
    + 系统调用：连接用户模式和内核模式的接口
    + 进程的虚拟地址空间：内核空间和用户空间。
        + 内核空间：存放内核代码和数据
        + 用户空间：存放用户代码和数据
    + 虚拟文件系统：
        + 一个操作系统可以支持底层多个不同的文件系统，为了给内核和用户一个统一的文件系统视图，linux在用户进程和底层文件系统之间增加了一个抽象层，就是虚拟文件系统（Virtual File System，VFS），进程所有的文件操作都是通过VFS，由VFS来适配各种底层不同的文件系统，完成实际的文件操作。
        + 主要模块：
            + 超级块(super_block),用于保存一个文件系统的所有元数据，相当于这个文件系统的信息库，为其他的模块提供信息。因此一个超级快可代表一个文件系统。文件系统的任意元数据修改都要修改超级块。超级块对象是常驻内存的并且被缓存的。
            + 目录项模块，管理路径的目录项。
            + inode模块，管理一个具体的文件，是文件的唯一标识，一个文件对一个inode。
            + 打开文件列表模块，包含所有内核已经打开的文件。已经打开的文件对象由open系统调用在内核中创建，也叫文件句柄。打开文件列表模块中包含一个列表，每个列表表项是一个结构体struct file，结构体中的信息用来表示打开的文件的各种状态参数。
            + file_operations模块。这个模块维护一个数据结构，是一系列函数指针的集合，其中包含了所有可以使用的系统调用函数。每个打开文件都可以连接到file_operations模块，从而对任何已打开的文件，通过系统调用函数，实现各种操作。
            + address_space模块，它表是一个文件在页缓存中已经缓存了的物理页。它是页缓存和外部设备中文件系统的桥梁。如果将文件系统视为数据源，那么address_space可以说关联了文件系统和内存系统。
    + I/O缓冲区
        + Buffer和Cache
            + cache：高速缓存，用于CPU和内存之间的缓冲
            + buffer：I/O缓存，用于内存和硬盘的缓冲
            + cache是加速读，而buffer是缓冲写，前者解决了读的问题，保存从磁盘上读的数据，后者解决写的问题，保存即将要写入到磁盘的内容。
            + Buffer Cache和Page Cache
                + 两者都是为了处理设备和内存交互时告诉访问的问题
                + Buffer Cache称为块缓冲区，Page Cache称为页缓冲区。
                + 两者最大的区别就是缓存的粒度。

    + 关键名词解释：
        + 上下文切换：当用户程序向系统内核发起系统调用时，CPU将用户进程从用户态切换到内核态；当系统调用完成返回时，CPU将用户进程从内核态切换回用户态。
        + CPU拷贝：由CPU直接处理数据的传输，数据拷贝时会一直占用CPU资源
        + DMA拷贝：由CPU向DMA磁盘控制下达指令，让DMA来处理数据的传送，数据传送完毕再把信息反馈给CPU，从而减轻了CPU资源的占有率。
        + 当应用程序执行read系统调用读取一块数据的时候，如果这块数据已经存在于用户进程的页内存中，就直接从内存中读取数据；如果数据不存在，则先将数据从磁盘加载数据到内核空间的读缓存(read buffer)中，再从读缓存拷贝到用户进程的页内存中。
    + 零拷贝方式：
        + Linux 中零拷贝技术主要有 3 个实现思路：用户态直接 I/O、减少数据拷贝次数以及写时复制技术。
            + 用户态直接 I/O：应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I/O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。
                + 缺点：这种方法只能适用于那些不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表。  
                  这种方法直接操作磁盘 I/O，由于 CPU 和磁盘 I/O 之间的执行时间差距，会造成资源的浪费，解决这个问题需要和异步 I/O 结合使用。
            + 减少数据拷贝次数：在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前主流零拷贝技术的实现思路。
                + mmap + write
                    + 一种零拷贝方式是使用 mmap + write 代替原来的 read + write 方式，减少了 1 次 CPU 拷贝操作
                    + 缺陷：mmap 主要的用处是提高 I/O 性能，特别是针对大文件。对于小文件，内存映射文件反而会导致碎片空间的浪费，因为内存映射总是要对齐页边界，最小单位是 4 KB，一个 5 KB 的文件将会映射占用 8 KB 内存，也就会浪费 3 KB 内存。
                    + 基于 mmap + write 系统调用的零拷贝方式，整个拷贝过程会发生 4 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝，用户程序读写数据的流程如下：
                        + 用户进程通过mmap()函数向内核(kernel)发起系统调用，上下文从用户态(user space)切换为内核态(kernel space)；
                        + 将用户进程的内核空间的读缓冲区(read buffer)和用户空间的缓冲区(user buffer)进行地址内存映射
                        + CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间(kernel space)的读缓冲区（read buffer）
                        + 上下文从内核态切换为用户太，mmap系统调用执行返回
                        + 用户进程通过write函数向内核发起系统调用，上下文从用户态切换为内核态;
                        + CPU将读缓存区中的数据拷贝到网络缓冲区
                        + CPU利用DMA从网络缓冲区拷贝到网卡进行数据传输
                        + 上下文从内核态转换回用户态，write系统调用执行返回。
                + sendfile
                    + 通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝。与 mmap 内存映射方式不同的是， sendfile 调用中 I/O 数据对用户空间是完全不可见的。也就是说，这是一次完全意义上的数据传输过程。
                    + 基于 sendfile 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝，用户程序读写数据的流程如下：
                        + 用户进程铜鼓sendfile函数向内核发起系统调用，上下文从用户态切换为内核态；
                        + CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间的读缓冲区。
                        + CPU将读缓冲区中的数据拷贝到的网络缓冲区。
                        + CPU利用DMA控制器将数据从网络缓冲区拷贝到网卡进行数据传输。
                        + 上下文从内核态切换回用户态，sendfile系统调用执行返回
                    + 相比较于 mmap 内存映射的方式，sendfile 少了 2 次上下文切换，但是仍然有 1 次 CPU 拷贝操作。sendfile 存在的问题是用户程序不能对数据进行修改，而只是单纯地完成了一次数据传输过程。
                    + 缺陷：只适用于那些不需要用户态处理的应用程序
                + sendfile + DMA gather copy
                    + 基于 sendfile + DMA gather copy 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下（这个对CPU次数的说法保留疑问）：
                        + 用户进程通过sendfile函数想内核发起系统调用，上下文从用户态切换到内核态；
                        + CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间的读缓冲区
                        + CPU把读缓冲区的文件描述(file descriptor)和数据长度拷贝到网络缓冲区(socket buffer)
                        + 基于已拷贝的文件描述和数据长度，CPU利用DMA控制器的gather/scatter操作直接批量地将数据从内核的读缓冲区拷贝到网卡进行数据传输。
                        + 上下文从内核态切换回用户态，sendfile系统调用执行返回
                    + 缺陷：sendfile+DMA gather copy拷贝方式同样存在用户进程不能对数据进行修改的问题，而且本身需要硬件的支持，它只适用于将数据文件拷贝到socket套接字上的传输过程

                + splice
                    + splice系统调用可以在内核空间的读缓冲区和网络缓冲区之间建立管道(pipeline)，从而避免了两者之间的CPU拷贝操作
                    + 基于 splice 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换，0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下：
                        + 用户进程通过splice函数向内核发起调用，上下文从用户态切换到内核态
                        + CPU通过DMA控制器将数据从主存或者硬盘拷贝到内核空间的读缓冲区
                        + CPU在内核空间的读缓冲区和网络缓冲区之间建立管道
                        + CPU直接通过DMA控制器将数据从网络缓冲区拷贝到网卡进行数据传输
                        + 上下文从内核态切回用户态，splice系统调用执行返回
                    + 缺陷：splice的方式同样存在用户程序不能对数据进行修改的问题。除此之外，它使用linux管道缓冲机制，可以用于任意两个文件描述符中传输数据，但是它的两个文件描述符参数中有一个必须是管道设备。

        + 写时复制技术：写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。
            + 缺点：需要 MMU 的支持，MMU 需要知道进程地址空间中哪些页面是只读的，当需要往这些页面写数据时，发出一个异常给操作系统内核，内核会分配新的存储空间来供写入的需求。
    + 参考：  
      https://blog.csdn.net/weixin_39551103/article/details/114617134

# 问题排查

1. 线上问题都有哪些手段？
    + 日志跟踪

    + arthas ali提供的java线上应用诊断利器   
      参考：https://arthas.aliyun.com/zh-cn/

# 系统架构

1. 大型互联网系统的特点：
    + 高并发和大流量
    + 高可用
    + 海量的数据存储
    + 用户分布广泛，网络情况复杂
    + 安全环境恶劣
    + 需求变化快，发布频繁
    + 系统能力提升的两种途径
        + 垂直伸缩：提升单台服务器的处理能力。
        + 水平伸缩：不是说提升单机的能力，而是使用集群的方式来提升
        + 垂直伸缩的局限：
            1. 当垂直伸缩达到一定程度以后，继续增加计算需要花费更多的费用。
            2. 垂直伸缩是有物理极限的
            3. 操作系统的设计或者是应用程序的设计制约着垂直伸缩。
2. 大型互联网架构的演进：
    + 单机系统->数据库与用户分离->使用缓存改善性能；应用服务集群化->使用反向代理和CDN加速响应；数据库读写分离->使用分布式文件系统和分布式数据库系统->使用搜索引擎、NoSql、消息队列与分布式服务
3. 分布式缓存
    + 使用缓存需要注意以下几点：
        1. 数据频繁修改，缓存效果比较差
        2. 数据没有热点，这类数据缓存命中率低
        3. 数据不一致，因为缓存的数据和数据库数据是不同的，可能存在数据不一致的情况，如果需要强一致性，使用缓存需要酌情考虑
        4. 缓存雪崩，当缓存崩溃的时候，可能会致使系统崩溃，这也是使用缓存需要注意的一点
    + 缓存的特点： 技术简单，性能提升显著，应用场景多
    + 缓存提升性能的优势：
        1. 数据来自于内存，访问速度更快
        2. 存储的数据形态通常是数据的最终形态，减少资源小号
        3. 可以有效降低数据库的磁盘或者网络的负载压力
    + 缓存数据的额存储：
        + 缓存使用的主要的数据结构就是哈希表
    + 缓存的关键指标：命中率
        + 影响命中率的三要素：
            + 缓存键集合大小
                + 要尽量减少键的数量，键的数量越小，缓存的效率越高。
            + 内存空间大小
                + 物理上缓存的空间越大，缓存的对象越多，缓存的命中率也就越高。
            + 缓存对象的生存时间（缓存寿命）
                + 缓存对象的生存时间成为TTL。对象缓存的时间越长，被重用的可能性就越高。
                + 缓存失效的方法有两种：超时失效和清除失效
                    + 超时失效：在构建缓存也就是写缓存的时候，每个缓存都设置了一个超时时间，在超时之前每次访问都会获取到对应的数据，但是一旦超时，缓存就失效了，再次访问缓存的时候就会获取到空。
                    + 清除失效：对象缓存更新的时候，直接通知缓存将已经被更新的数据对象进行清除。这时候访问缓存就会去数据库进行获取，然后获取到目标数据，因为数据库中的数据总是更新后最新的数据。
                    + 还有一种就是需要将对象写入缓存，缓存空间不够，这时候就需要将一些老的缓存对象进行清除，为新的缓存腾出空间
                    + 内存清除对象主要使用的是LRU算法，该算法就是最近最久未用算法，也就是清除那些最近最久没有被使用过的对象。
                        + 这个算法是使用链表结构进行实现的，所有缓存的对象都放在同一个链表上，当一个对象被访问的时候，就把这个对象移动到整个链表的头部。当需要通过LRU算法进行删除的时候，只需要将链表尾部的进行清除即可。
    + 缓存的主要类型：
        + 通读缓存：
            + 代理缓存：应用程序一端的代理，缓存在客户端一端的，代理客户端访问互联网。由于是在客户端一端我们是无法进行管理的，所以虽然代理缓存是存在的，但是通常不算是我们系统架构的一部分。
            + 反向代理缓存：是代理数据中心输出的，是反向代理的。所以反向代理缓存是存在于系统数据中心里的，它是数据中心的统一入口，代理整个数据中心其他应服务器的应用处理。
            + 内容分发网络CDN缓存：在用户请求的前端（尽量前的前端）为用户提供数据服务。
        + 旁路缓存：
    + 使用注意事项：
        + 合理使用缓存对象
        + 注意频繁修改的数据： 一般读写比例为2：1的数据才有意义
        + 注意没有热点的访问数据
        + 注意数据不一致和脏读
        + 注意缓存雪崩

4. 分布式消息队列
    + 同步调用和异步调用
        + 同步调用：就是说从请求的发起一直到最终的处理完成期间，请求的调用方一直处于同步阻塞，等待调用的处理完成。
        + 异步调用：一个可以无需等待被调用函数的返回值就让操作继续进行的方法
    + 点对点模型和发布/订阅模型对比：
        + 通常使用点对点模型的都是一些耗时比较长的，逻辑相对独立的业务。
    + 好处：异步处理、易伸缩、使峰值变平缓、失败隔离及自我修复、解耦
    + 消息队列的挑战：消息无序，消息重新入队列，竞态条件，复杂度风险。
        + 消息无序： 消息本身的创建是有序的，但是消费者确不能保证先创建的消息先消费。
        + 消息重新入队（消息重复消费）： 解决重复消费问题，主要手段就是需要将消息系统设计成幂等性的，也就是说消费者可以对同一条消息进行多次处理计算，而不会影响最终的结果。
        + 竞态条件： 程序在并发执行的时候，不同的执行顺序会导致不同的结果，主要是对共享资源访问顺序不同导致的结果不同。在编程中一般使用锁机制进行并发的控制，避免竞态、顺序执行。
        + 复杂度风险：
    + 消息队列的反模式：
        + 阻塞式调用：
        + 耦合生产者和消费者：
        + 缺少坏消息处理
    + 常用消息队列产品：RabbitMQ，ActiveMQ，RocketMQ，Kafka
        + RabbitMQ性能好
        + ActiveMQ影响比较广泛，可以跨平台，使用Java开发，对Java开发程序员比较友好。
        + RocketMQ是阿里推出的一个开源产品，也是使用Java开发，性能比较好，可靠性比较高。
        + Kafka专门针对分布式进行了优化，因此分布式的伸缩性比较好。

5. 分布式数据存储
    + 一主多从复制的优点：分摊负载、专机专用、便于冷备、高可用
        + 分摊负载： 一般是为了进行读写分离，可以有效的将访问压力进行分摊
        + 专机专用：
        + 便于冷备：
        + 高可用：
    + 主主复制：为了解决服务器的可用性问题。两台服务器都当作主服务器，任何一台服务器上收到写操作都会同步到另一台机器上面。
    + 数据库部署方案：
        + 单一服务和单一数据库：
        + 主从复制：
        + 业务分库：随着业务更加复杂，为了提供更高的数据库处理能力，可以进行数据的业务分库。数据的业务分库是一种逻辑上的，是基于功能的一种分割，将不同用途的数据库表存储在不同的物理数据库上面去。
        + 综合部署：
    + NoSQL数据库：
    + CAP原理和数据一致性：对于一个分布式系统，它不能同时满足一致性(C)、可用性(A)以及分区耐受性(P)这三个特点。
        + 一致性：任何时刻集群中所有的数据的备份都是一致的
        + 可用性：当分布式集群中某些服务器节点失效的时候，集群已然是可用的。
        + 分区耐受性：当网络失效的时候，节点无法通信的时候，系统依然是可用的。
        + 通常情况下，一个分布式应用系统，可用性是必不可少的，而分区耐受性也是需要满足的。因此在现实中，很多系统是通过对数据的一致性做文章，来提供一个满足要求的分布式系统。
    + 一致性冲突解决方案：
        + 最终一致性：再一个分布式系统中，在某个时候，不同服务器上存储的同一个数据可能是不一致的，但是他最终还是一致的，只要不一致的时间不影响应用程序的正确性，我们就是可以接受的。
    
6. 微服务
    + 单体系统的困难：
        + 编译部署困难
        + 代码分支管理困难
        + 数据库链接耗尽
        + 新增业务困难
    + 微服务架构
        + SOA架构
        + DUBBO架构
        + SpringCloud
    + 微服务架构策略
    + 微服务使用模式
        + 事件溯源：微服务的调用比较复杂，调用链路可能会比较长。
            + 好处一：可以精确地复现用户的状态变化
            + 好处二：可以有效监控用户的监控变化，并在此基础上实现分布式的事务